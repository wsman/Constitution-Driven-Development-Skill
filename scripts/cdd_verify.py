#!/usr/bin/env python3
"""
CDD Skill Verification Tool (cdd_verify.py) v2.0.0
==================================================
éªŒè¯CDDæŠ€èƒ½çš„å®Œæ•´æ€§ï¼ŒåŒ…æ‹¬æ–‡ä»¶ã€ä¾èµ–ã€æ¨¡æ¿å’Œé…ç½®æ£€æŸ¥ã€‚

å®ªæ³•ä¾æ®: Â§100.3, Â§101, Â§106.1

Usage:
    python scripts/cdd_verify.py                    # åŸºæœ¬éªŒè¯
    python scripts/cdd_verify.py --full             # å®Œæ•´éªŒè¯
    python scripts/cdd_verify.py --fix              # å°è¯•è‡ªåŠ¨ä¿®å¤
    python scripts/cdd_verify.py --json             # JSONæ ¼å¼è¾“å‡º
"""

import sys
import os
import json
import subprocess
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
SCRIPT_DIR = Path(__file__).resolve().parent
SKILL_ROOT = SCRIPT_DIR.parent
sys.path.insert(0, str(SKILL_ROOT))

VERSION = "2.0.0"

# -----------------------------------------------------------------------------
# æ ¸å¿ƒæ–‡ä»¶åˆ—è¡¨
# -----------------------------------------------------------------------------

CORE_FILES = {
    "root": [
        "README.md",
        "SKILL.md",
        "QUICK_START.md",
        "reference.md",
        "pyproject.toml",
        "requirements.txt",
        "pytest.ini",
        "Makefile",
    ],
    "scripts": [
        "scripts/cdd_check_env.py",
        "scripts/cdd_feature.py",
        "scripts/cdd_auditor.py",
        "scripts/cdd_entropy.py",
        "scripts/cdd_claude_bridge.py",
        "scripts/cdd_utils.py",
    ],
    "core": [
        "core/__init__.py",
        "core/constitution_core.py",
        "core/constants.py",
        "core/exceptions.py",
        "core/audit_service.py",
        "core/entropy_service.py",
        "core/feature_service.py",
        "core/state_transition_service.py",
        "core/state_validation_service.py",
    ],
    "utils": [
        "utils/__init__.py",
        "utils/cache_manager.py",
        "utils/entropy_utils.py",
        "utils/file_utils.py",
        "utils/logger.py",
        "utils/spore_utils.py",
        "utils/version_utils.py",
    ],
    "templates_t0": [
        "templates/t0_core/active_context.md",
        "templates/t0_core/knowledge_graph.md",
        "templates/t0_core/basic_law_index.md",
        "templates/t0_core/operational_law_index.md",
    ],
    "templates_t1": [
        "templates/t1_axioms/system_patterns.md",
        "templates/t1_axioms/tech_context.md",
        "templates/t1_axioms/behavior_context.md",
    ],
    "templates_t2_protocols": [
        "templates/t2_protocols/WF-001_clarify_workflow.md",
        "templates/t2_protocols/WF-201_cdd_workflow.md",
        "templates/t2_protocols/WF-206_refactor_protocol.md",
    ],
    "templates_t2_standards": [
        "templates/t2_standards/DS-007_context_management.md",
        "templates/t2_standards/DS-039_tool_bridge.md",
        "templates/t2_standards/DS-050_feature_specification.md",
        "templates/t2_standards/DS-051_implementation_plan.md",
        "templates/t2_standards/DS-052_atomic_tasks.md",
        "templates/t2_standards/DS-053_quality_checklist.md",
        "templates/t2_standards/DS-054_environment_hardening.md",
        "templates/t2_standards/DS-055_entropy_optimizer_spec.md",
        "templates/t2_standards/DS-060_code_review.md",
    ],
}

# -----------------------------------------------------------------------------
# ä¾èµ–åˆ—è¡¨
# -----------------------------------------------------------------------------

DEPENDENCIES = {
    "python": {
        "min_version": (3, 8),
        "check_fn": lambda: check_python_version(),
        "install_cmd": None,
        "required": True,
    },
    "pytest": {
        "min_version": (6, 0),
        "check_fn": lambda: check_pytest_version(),
        "install_cmd": "pip install pytest",
        "required": True,
    },
    "pyyaml": {
        "min_version": (6, 0),
        "check_fn": lambda: check_pyyaml_version(),
        "install_cmd": "pip install pyyaml",
        "required": True,
    },
}

# -----------------------------------------------------------------------------
# æ£€æŸ¥å‡½æ•°
# -----------------------------------------------------------------------------

def check_python_version() -> Tuple[bool, str, Optional[str]]:
    """æ£€æŸ¥Pythonç‰ˆæœ¬"""
    min_version = (3, 8)
    current_version = (sys.version_info.major, sys.version_info.minor)
    
    if current_version >= min_version:
        version_str = f"{current_version[0]}.{current_version[1]}.{sys.version_info.micro}"
        return True, version_str, None
    
    version_str = f"{current_version[0]}.{current_version[1]}.{sys.version_info.micro}"
    return False, version_str, f"Python {min_version[0]}.{min_version[1]}+ required"

def check_pytest_version() -> Tuple[bool, str, Optional[str]]:
    """æ£€æŸ¥pytestç‰ˆæœ¬"""
    try:
        import pytest
        version = pytest.__version__
        import re
        match = re.search(r'(\d+)\.(\d+)\.(\d+)', version)
        if match:
            major = int(match.group(1))
            if major >= 6:
                return True, version, None
        return True, version, f"pytest 6.0+ recommended"
    except ImportError:
        return False, None, "pytest not installed"

def check_pyyaml_version() -> Tuple[bool, str, Optional[str]]:
    """æ£€æŸ¥PyYAMLç‰ˆæœ¬"""
    try:
        import yaml
        return True, yaml.__version__, None
    except ImportError:
        return False, None, "PyYAML not installed"

def check_file_exists(file_path: Path) -> Tuple[bool, Optional[str]]:
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    if file_path.exists():
        return True, None
    return False, f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path.relative_to(SKILL_ROOT)}"

def check_file_readable(file_path: Path) -> Tuple[bool, Optional[str]]:
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å¯è¯»"""
    if not file_path.exists():
        return False, f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            f.read(1024)  # è¯»å–å‰1KBéªŒè¯
        return True, None
    except Exception as e:
        return False, f"æ–‡ä»¶ä¸å¯è¯»: {file_path} - {e}"

# -----------------------------------------------------------------------------
# éªŒè¯å‡½æ•°
# -----------------------------------------------------------------------------

def verify_core_files(full: bool = False) -> Dict[str, Any]:
    """éªŒè¯æ ¸å¿ƒæ–‡ä»¶å®Œæ•´æ€§"""
    results = {
        "category": "core_files",
        "description": "æ ¸å¿ƒæ–‡ä»¶å®Œæ•´æ€§",
        "status": "passed",
        "files_checked": 0,
        "files_passed": 0,
        "issues": []
    }
    
    categories_to_check = ["root", "scripts", "core", "utils"]
    if full:
        categories_to_check.extend(["templates_t0", "templates_t1", 
                                   "templates_t2_protocols", "templates_t2_standards"])
    
    for category in categories_to_check:
        if category not in CORE_FILES:
            continue
        
        for file_path_str in CORE_FILES[category]:
            file_path = SKILL_ROOT / file_path_str
            results["files_checked"] += 1
            
            passed, error = check_file_exists(file_path)
            if not passed:
                results["status"] = "failed"
                results["issues"].append({"file": file_path_str, "error": error})
                continue
            
            if full:
                passed, error = check_file_readable(file_path)
                if not passed:
                    results["status"] = "failed"
                    results["issues"].append({"file": file_path_str, "error": error})
                    continue
            
            results["files_passed"] += 1
    
    return results

def verify_dependencies(full: bool = False) -> Dict[str, Any]:
    """éªŒè¯ä¾èµ–å®Œæ•´æ€§"""
    results = {
        "category": "dependencies",
        "description": "ä¾èµ–å®Œæ•´æ€§",
        "status": "passed",
        "deps_checked": 0,
        "deps_passed": 0,
        "issues": []
    }
    
    for dep_name, dep_config in DEPENDENCIES.items():
        results["deps_checked"] += 1
        
        installed, version, error = dep_config["check_fn"]()
        
        if not installed:
            results["status"] = "failed"
            results["issues"].append({
                "dependency": dep_name,
                "error": error,
                "install_cmd": dep_config.get("install_cmd"),
                "required": dep_config.get("required", False)
            })
            continue
        
        results["deps_passed"] += 1
    
    # æ£€æŸ¥Pythonæ¨¡å—å¯¼å…¥
    if full:
        modules_to_check = [
            ("core.constitution_core", "core/constitution_core.py"),
            ("core.audit_service", "core/audit_service.py"),
            ("core.entropy_service", "core/entropy_service.py"),
            ("core.feature_service", "core/feature_service.py"),
            ("utils.spore_utils", "utils/spore_utils.py"),
        ]
        
        for module_name, file_path in modules_to_check:
            try:
                __import__(module_name)
            except ImportError as e:
                results["status"] = "failed"
                results["issues"].append({
                    "module": module_name,
                    "error": f"å¯¼å…¥å¤±è´¥: {e}",
                    "file": file_path
                })
    
    return results

def verify_config_files() -> Dict[str, Any]:
    """éªŒè¯é…ç½®æ–‡ä»¶å®Œæ•´æ€§"""
    results = {
        "category": "config_files",
        "description": "é…ç½®æ–‡ä»¶å®Œæ•´æ€§",
        "status": "passed",
        "files_checked": 0,
        "files_passed": 0,
        "issues": []
    }
    
    config_files = [
        "pytest.ini",
        "pyproject.toml",
        "requirements.txt",
    ]
    
    for file_name in config_files:
        file_path = SKILL_ROOT / file_name
        results["files_checked"] += 1
        
        passed, error = check_file_exists(file_path)
        if not passed:
            results["status"] = "failed"
            results["issues"].append({"file": file_name, "error": error})
            continue
        
        # éªŒè¯YAMLé…ç½®æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if file_name.endswith('.yaml') or file_name.endswith('.yml'):
            try:
                import yaml
                with open(file_path, 'r', encoding='utf-8') as f:
                    yaml.safe_load(f)
            except Exception as e:
                results["status"] = "failed"
                results["issues"].append({
                    "file": file_name,
                    "error": f"YAMLè§£æå¤±è´¥: {e}"
                })
                continue
        
        results["files_passed"] += 1
    
    return results

def verify_structure() -> Dict[str, Any]:
    """éªŒè¯ç›®å½•ç»“æ„"""
    results = {
        "category": "structure",
        "description": "ç›®å½•ç»“æ„",
        "status": "passed",
        "directories_checked": 0,
        "directories_passed": 0,
        "issues": []
    }
    
    required_dirs = [
        "core",
        "scripts",
        "templates",
        "utils",
        "reference",
        "claude",
    ]
    
    for dir_name in required_dirs:
        dir_path = SKILL_ROOT / dir_name
        results["directories_checked"] += 1
        
        if not dir_path.exists() or not dir_path.is_dir():
            results["status"] = "failed"
            results["issues"].append({
                "directory": dir_name,
                "error": "ç›®å½•ä¸å­˜åœ¨"
            })
            continue
        
        results["directories_passed"] += 1
    
    return results


# -----------------------------------------------------------------------------
# æ¨¡æ¿å¿…éœ€æ–‡ä»¶
# -----------------------------------------------------------------------------

REQUIRED_TEMPLATES = {
    "t0_core": [
        "templates/t0_core/active_context.md",
        "templates/t0_core/knowledge_graph.md",
        "templates/t0_core/basic_law_index.md",
        "templates/t0_core/operational_law_index.md",
        "templates/t0_core/tools_law_index.md",
    ],
    "t1_axioms": [
        "templates/t1_axioms/behavior_context.md",
        "templates/t1_axioms/system_patterns.md",
        "templates/t1_axioms/tech_context.md",
    ],
    "t2_protocols": [
        "templates/t2_protocols/WF-001_clarify_workflow.md",
        "templates/t2_protocols/WF-201_cdd_workflow.md",
        "templates/t2_protocols/WF-206_refactor_protocol.md",
    ],
    "t2_standards": [
        "templates/t2_standards/DS-007_context_management.md",
        "templates/t2_standards/DS-039_tool_bridge.md",
        "templates/t2_standards/DS-050_feature_specification.md",
        "templates/t2_standards/DS-051_implementation_plan.md",
        "templates/t2_standards/DS-052_atomic_tasks.md",
        "templates/t2_standards/DS-053_quality_checklist.md",
    ],
    "t3_documentation": [
        "templates/t3_documentation/unified_docs.md",
    ],
}


def verify_templates(full: bool = False) -> Dict[str, Any]:
    """éªŒè¯æ¨¡æ¿å®Œæ•´æ€§"""
    results = {
        "category": "templates",
        "description": "æ¨¡æ¿å®Œæ•´æ€§",
        "status": "passed",
        "templates_checked": 0,
        "templates_passed": 0,
        "issues": [],
        "details": {}
    }
    
    for group_name, templates in REQUIRED_TEMPLATES.items():
        group_passed = 0
        group_total = len(templates)
        
        for template_path_str in templates:
            template_path = SKILL_ROOT / template_path_str
            results["templates_checked"] += 1
            
            if not template_path.exists():
                results["status"] = "failed"
                results["issues"].append({
                    "template": template_path_str,
                    "group": group_name,
                    "error": "æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨"
                })
                continue
            
            # æ£€æŸ¥æ¨¡æ¿æ–‡ä»¶æ˜¯å¦æœ‰å†…å®¹
            if full:
                try:
                    content = template_path.read_text(encoding='utf-8')
                    if len(content.strip()) < 50:  # æ¨¡æ¿è‡³å°‘è¦æœ‰50å­—ç¬¦
                        results["status"] = "warning"
                        results["issues"].append({
                            "template": template_path_str,
                            "group": group_name,
                            "error": "æ¨¡æ¿å†…å®¹è¿‡çŸ­ï¼Œå¯èƒ½æ˜¯ç©ºæ¨¡æ¿"
                        })
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«æœªè§£æçš„æ¨¡æ¿å˜é‡
                    import re
                    unresolved_vars = re.findall(r'\{\{[A-Z_]+\}\}', content)
                    # æ³¨æ„ï¼šæ¨¡æ¿æ–‡ä»¶ä¸­åŒ…å«æ¨¡æ¿å˜é‡æ˜¯æ­£å¸¸çš„
                    
                except Exception as e:
                    results["status"] = "failed"
                    results["issues"].append({
                        "template": template_path_str,
                        "group": group_name,
                        "error": f"æ— æ³•è¯»å–æ¨¡æ¿: {e}"
                    })
                    continue
            
            results["templates_passed"] += 1
            group_passed += 1
        
        results["details"][group_name] = {
            "total": group_total,
            "passed": group_passed
        }
    
    return results

# -----------------------------------------------------------------------------
# ä¿®å¤å‡½æ•°
# -----------------------------------------------------------------------------

def attempt_fix(issue: Dict[str, Any], verbose: bool = False) -> Tuple[bool, str]:
    """å°è¯•ä¿®å¤é—®é¢˜"""
    issue_type = issue.get("type", "unknown")
    
    if issue_type == "dependency":
        install_cmd = issue.get("install_cmd")
        if not install_cmd:
            return False, "æ— è‡ªåŠ¨ä¿®å¤æ–¹æ¡ˆ"
        
        if verbose:
            print(f"å°è¯•å®‰è£…: {issue.get('dependency')}")
            print(f"å‘½ä»¤: {install_cmd}")
        
        try:
            result = subprocess.run(install_cmd, shell=True,
                                   capture_output=True, text=True,
                                   timeout=60)
            
            if result.returncode != 0:
                return False, f"å®‰è£…å¤±è´¥: {result.stderr[:100]}"
            
            return True, "å®‰è£…æˆåŠŸ"
        except Exception as e:
            return False, f"å®‰è£…é”™è¯¯: {e}"
    
    return False, "æ— æ³•è‡ªåŠ¨ä¿®å¤"

# -----------------------------------------------------------------------------
# è¾“å‡ºæ ¼å¼åŒ–
# -----------------------------------------------------------------------------

def format_text_output(results: List[Dict[str, Any]], show_details: bool = False) -> str:
    """æ–‡æœ¬æ ¼å¼è¾“å‡º"""
    lines = [f"ğŸ” CDDæŠ€èƒ½éªŒè¯ v{VERSION}"]
    lines.append(f"{'='*50}")
    
    overall_status = "âœ… é€šè¿‡" if all(r["status"] == "passed" for r in results) else "âŒ å¤±è´¥"
    lines.append(f"æ€»ä½“çŠ¶æ€: {overall_status}\n")
    
    for result in results:
        icon = "âœ…" if result["status"] == "passed" else "âŒ"
        lines.append(f"{icon} {result['description']}")
        
        if result["status"] == "passed":
            if "files_checked" in result:
                lines.append(f"   æ–‡ä»¶: {result['files_passed']}/{result['files_checked']}")
            if "deps_checked" in result:
                lines.append(f"   ä¾èµ–: {result['deps_passed']}/{result['deps_checked']}")
            if "directories_checked" in result:
                lines.append(f"   ç›®å½•: {result['directories_passed']}/{result['directories_checked']}")
        else:
            lines.append(f"   âŒ å‘ç° {len(result.get('issues', []))} ä¸ªé—®é¢˜")
            
            if show_details:
                for issue in result.get("issues", []):
                    lines.append(f"      â€¢ {issue.get('error', 'Unknown error')}")
                    if "install_cmd" in issue:
                        lines.append(f"        ä¿®å¤: {issue['install_cmd']}")
        
        lines.append("")
    
    # æ±‡æ€»ä¿¡æ¯
    total_issues = sum(len(r.get("issues", [])) for r in results)
    if total_issues > 0:
        lines.append(f"ğŸ“Š æ€»è®¡å‘ç° {total_issues} ä¸ªé—®é¢˜")
        lines.append(f"ğŸ’¡ è¿è¡Œ 'python scripts/cdd_verify.py --fix' å°è¯•è‡ªåŠ¨ä¿®å¤")
    
    return "\n".join(lines)

def format_json_output(results: List[Dict[str, Any]]) -> str:
    """JSONæ ¼å¼è¾“å‡º"""
    output = {
        "version": VERSION,
        "timestamp": subprocess.run(["date", "-Iseconds"],
                                   capture_output=True, text=True).stdout.strip(),
        "overall_status": "passed" if all(r["status"] == "passed" for r in results) else "failed",
        "results": results,
        "summary": {
            "categories_checked": len(results),
            "categories_passed": sum(1 for r in results if r["status"] == "passed"),
            "total_issues": sum(len(r.get("issues", [])) for r in results),
        }
    }
    return json.dumps(output, indent=2, ensure_ascii=False)

# -----------------------------------------------------------------------------
# ä¸»å‡½æ•°
# -----------------------------------------------------------------------------

def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description=f"CDD Skill Verification v{VERSION}",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python scripts/cdd_verify.py              # åŸºæœ¬éªŒè¯
  python scripts/cdd_verify.py --full       # å®Œæ•´éªŒè¯
  python scripts/cdd_verify.py --fix        # å°è¯•è‡ªåŠ¨ä¿®å¤
  python scripts/cdd_verify.py --json       # JSONæ ¼å¼è¾“å‡º
        """
    )
    
    parser.add_argument("--full", "-f", action="store_true",
                       help="å®Œæ•´éªŒè¯ï¼ˆåŒ…æ‹¬æ¨¡æ¿å’Œæ¨¡å—å¯¼å…¥ï¼‰")
    parser.add_argument("--fix", action="store_true",
                       help="å°è¯•è‡ªåŠ¨ä¿®å¤é—®é¢˜")
    parser.add_argument("--verbose", "-v", action="store_true",
                       help="è¯¦ç»†è¾“å‡º")
    parser.add_argument("--json", "-j", action="store_true",
                       help="JSONæ ¼å¼è¾“å‡º")
    parser.add_argument("--quiet", "-q", action="store_true",
                       help="å®‰é™æ¨¡å¼ï¼ˆä»…æ˜¾ç¤ºé”™è¯¯ï¼‰")
    
    args = parser.parse_args()
    
    # æ‰§è¡ŒéªŒè¯
    results = []
    
    # 1. éªŒè¯ç›®å½•ç»“æ„
    results.append(verify_structure())
    
    # 2. éªŒè¯æ ¸å¿ƒæ–‡ä»¶
    results.append(verify_core_files(full=args.full))
    
    # 3. éªŒè¯ä¾èµ–
    results.append(verify_dependencies(full=args.full))
    
    # 4. éªŒè¯é…ç½®æ–‡ä»¶
    results.append(verify_config_files())
    
    # 5. éªŒè¯æ¨¡æ¿ï¼ˆå®Œæ•´æ¨¡å¼ä¸‹ï¼‰
    if args.full:
        results.append(verify_templates(full=True))
    
    # å°è¯•ä¿®å¤
    if args.fix:
        fixes_attempted = 0
        fixes_succeeded = 0
        
        for result in results:
            if result["status"] == "failed":
                for issue in result.get("issues", []):
                    if "install_cmd" in issue:
                        fix_issue = issue.copy()
                        fix_issue["type"] = "dependency"
                        
                        success, msg = attempt_fix(fix_issue, args.verbose)
                        fixes_attempted += 1
                        
                        if success:
                            fixes_succeeded += 1
                            # é‡æ–°éªŒè¯
                            if result["category"] == "dependencies":
                                new_result = verify_dependencies(full=args.full)
                                result["deps_checked"] = new_result["deps_checked"]
                                result["deps_passed"] = new_result["deps_passed"]
                                result["issues"] = new_result["issues"]
                                result["status"] = new_result["status"]
        
        if not args.quiet and fixes_attempted > 0:
            print(f"\nğŸ”§ ä¿®å¤æ‘˜è¦:")
            print(f"   å°è¯•ä¿®å¤: {fixes_attempted}")
            print(f"   æˆåŠŸä¿®å¤: {fixes_succeeded}")
            print(f"   å¤±è´¥ä¿®å¤: {fixes_attempted - fixes_succeeded}")
            print()
    
    # è¾“å‡ºç»“æœ
    if args.json:
        print(format_json_output(results))
    else:
        if not args.quiet:
            print(format_text_output(results, show_details=args.verbose))
        else:
            # ä»…æ˜¾ç¤ºå¤±è´¥ä¿¡æ¯
            failed_results = [r for r in results if r["status"] == "failed"]
            if failed_results:
                for result in failed_results:
                    print(f"âŒ {result['description']}")
                    for issue in result.get("issues", []):
                        print(f"   â€¢ {issue.get('error', 'Unknown error')}")
    
    # è®¾ç½®é€€å‡ºç 
    overall_passed = all(r["status"] == "passed" for r in results)
    sys.exit(0 if overall_passed else 1)

if __name__ == "__main__":
    main()